{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0174943-dbd5-4e4d-8e88-d0d50cada85b",
   "metadata": {},
   "source": [
    "### 1️⃣ PySpark'ı Başlatma ve SparkSession Oluşturma\n",
    "Bu adımda PySpark'ın çalışması için gerekli ortam değişkenlerini ayarlıyor ve bir **Spark oturumu (SparkSession)** oluşturuyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04b0fd9-cbed-4ed9-ac71-23d5968d8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# PySpark ve Java'nın yolunu tanımla\n",
    "os.environ[\"SPARK_HOME\"] = \"c:\\\\users\\\\bedirhan\\\\miniconda3\\\\envs\\\\veri_uygulamalari\\\\lib\\\\site-packages\\\\pyspark\"\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Eclipse Adoptium\\\\jdk-11.0.26.4-hotspot\"  # Java 11 yolunu doğrula\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# Spark oturumunu başlat\n",
    "spark = SparkSession.builder.appName(\"CaliforniaHousingRegression\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f10cb30-9e09-4a9d-9755-fd6288aa4665",
   "metadata": {},
   "source": [
    "### 2️⃣ CSV Dosyasını Okuma ve İlk 5 Satırı Görüntüleme\n",
    "Bu adımda **housing.csv** dosyasını PySpark DataFrame olarak yüklüyoruz.  \n",
    "- **`header=True`** → İlk satırı sütun isimleri olarak kullan.  \n",
    "- **`inferSchema=True`** → Sütunların veri tiplerini otomatik olarak belirle.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22060da1-361d-4745-a1f6-b0831e04773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Veriyi oku\n",
    "data_path = \"housing.csv\"  # Dosyanın bulunduğu dizini kontrol et!\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Verinin ilk 5 satırına bakalım\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff1688-3cba-46f2-8ecc-f5f6fc44de12",
   "metadata": {},
   "source": [
    "### 3️⃣ Verinin Şemasını (Schema) İnceleme\n",
    "Bu adımda verinin şemasını (sütun adları ve veri türlerini) görüntülüyoruz.  \n",
    "- **Hangi sütunların sayısal (`double`), hangi sütunların kategorik (`string`) olduğunu görebiliriz.**  \n",
    "- **Eksik değer alabilen (`nullable=True`) sütunları tespit edebiliriz.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d11f2de-a45a-46b2-8740-ca4646076549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64f15f-b83b-4343-b3a9-2e2dfd2ff6e9",
   "metadata": {},
   "source": [
    "### 4️⃣ Eksik Değerleri Sayma\n",
    "Bu adımda **veri setindeki eksik (boş) değerleri tespit ediyoruz.**  \n",
    "- **Her sütunda kaç tane eksik (null) değer olduğunu hesaplıyoruz.**  \n",
    "- **Sonucu tablo halinde ekrana yazdırıyoruz.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7125bdc7-8f6b-40c5-abca-5545f0f78506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|        0|       0|                 0|          0|           207|         0|         0|            0|                 0|              0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Eksik değerleri say\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfa509-6e00-44cb-b970-be5a9f0b6298",
   "metadata": {},
   "source": [
    "### 5️⃣ Kategorik Değerleri (Distinct) İnceleme  \n",
    "Bu adımda **\"ocean_proximity\"** sütunundaki **farklı (distinct) değerleri** inceliyoruz.  \n",
    "\n",
    "- **Bu sütunda tekrar eden değerleri kaldırarak benzersiz kategorileri gösteriyoruz.**  \n",
    "- **Çıktı, veride kaç farklı kategorik değer olduğunu anlamamızı sağlar.**  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70907d85-7b5f-4d2d-ab37-e924ff177918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|ocean_proximity|\n",
      "+---------------+\n",
      "|         ISLAND|\n",
      "|     NEAR OCEAN|\n",
      "|       NEAR BAY|\n",
      "|      <1H OCEAN|\n",
      "|         INLAND|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ocean_proximity\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047eb535-f9ea-4f3a-bb64-171e17b3d6bf",
   "metadata": {},
   "source": [
    "### 6️⃣ Veri Setinin İstatistiksel Özelliklerini İnceleme  \n",
    "Bu adımda **veri setindeki sayısal sütunların temel istatistiklerini** görüntülüyoruz.  \n",
    "\n",
    "**Çıktıda bulunan bilgiler:**  \n",
    "- **`count`** → Her sütundaki veri sayısı.  \n",
    "- **`mean`** → Ortalama değer.  \n",
    "- **`stddev`** → Standart sapma (veri yayılımı).  \n",
    "- **`min` ve `max`** → Minimum ve maksimum değerler.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f9eaa8-94b9-4a8b-af0e-e1fad912bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "|summary|          longitude|         latitude|housing_median_age|       total_rooms|    total_bedrooms|        population|       households|     median_income|median_house_value|ocean_proximity|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "|  count|              20640|            20640|             20640|             20640|             20433|             20640|            20640|             20640|             20640|          20640|\n",
      "|   mean|-119.56970445736148| 35.6318614341087|28.639486434108527|2635.7630813953488| 537.8705525375618|1425.4767441860465|499.5396802325581|3.8706710029070246|206855.81690891474|           NULL|\n",
      "| stddev|  2.003531723502584|2.135952397457101| 12.58555761211163|2181.6152515827944|421.38507007403115|  1132.46212176534|382.3297528316098| 1.899821717945263|115395.61587441359|           NULL|\n",
      "|    min|            -124.35|            32.54|               1.0|               2.0|               1.0|               3.0|              1.0|            0.4999|           14999.0|      <1H OCEAN|\n",
      "|    max|            -114.31|            41.95|              52.0|           39320.0|            6445.0|           35682.0|           6082.0|           15.0001|          500001.0|     NEAR OCEAN|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68aafb5-9881-4a4e-8f64-960c54eec6b8",
   "metadata": {},
   "source": [
    "### 7️⃣ Eksik Değerleri Ortalamayla Doldurma  \n",
    "Bu adımda **\"total_bedrooms\"** sütunundaki **eksik değerleri sütunun ortalaması ile dolduruyoruz.**  \n",
    "- Eksik verileri **ortalama değer ile doldurmak**, verinin dağılımını bozmadan tamamlama yöntemidir.  \n",
    "- **Eksik verilerin etkisini azaltarak modelimizin doğruluğunu artırabiliriz.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **\"total_bedrooms\"** sütununun ortalamasını hesapla.  \n",
    "2️⃣ **Eksik değerleri bu ortalama ile doldur.**  \n",
    "3️⃣ **Eksik veri olup olmadığını tekrar kontrol et.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4cd1903-b3cb-490d-96a5-7cdb1c369c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|        0|       0|                 0|          0|             0|         0|         0|            0|                 0|              0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "# total_bedrooms sütununun ortalamasını hesapla\n",
    "bedroom_mean = df.select(mean(col(\"total_bedrooms\"))).collect()[0][0]\n",
    "\n",
    "# Eksik değerleri ortalama ile doldur\n",
    "df = df.fillna({\"total_bedrooms\": bedroom_mean})\n",
    "\n",
    "# Kontrol edelim\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78e932-e659-4f53-a2f8-5d7444ba087b",
   "metadata": {},
   "source": [
    "### 8️⃣ Kategorik Değişkeni Sayısal Hale Getirme (`StringIndexer`)  \n",
    "Bu adımda **\"ocean_proximity\"** sütunundaki **metin (kategorik) değerleri sayısal değerlere çeviriyoruz.**  \n",
    "- Makine öğrenmesi modelleri sayısal verilerle çalıştığı için **kategorik sütunları sayısal hale getirmek gereklidir.**  \n",
    "- **\"StringIndexer\" en sık görülen kategoriyi 0, diğerlerini sırasıyla 1, 2, 3 olarak etiketler.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **\"ocean_proximity\" sütununu sayısal hale getir.**  \n",
    "2️⃣ **Yeni sütunu (\"ocean_proximity_index\") ekleyerek veri setini dönüştür.**  \n",
    "3️⃣ **Orijinal ve dönüştürülmüş sütunları göster.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fed5cc8-60bb-4527-b7cc-f9d897ef7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|ocean_proximity|ocean_proximity_index|\n",
      "+---------------+---------------------+\n",
      "|       NEAR BAY|                  3.0|\n",
      "|       NEAR BAY|                  3.0|\n",
      "|       NEAR BAY|                  3.0|\n",
      "|       NEAR BAY|                  3.0|\n",
      "|       NEAR BAY|                  3.0|\n",
      "+---------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# StringIndexer ile ocean_proximity kategorik sütununu sayısal hale çevir\n",
    "indexer = StringIndexer(inputCol=\"ocean_proximity\", outputCol=\"ocean_proximity_index\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Yeni sayısal sütunu göster\n",
    "df.select(\"ocean_proximity\", \"ocean_proximity_index\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff50cf4-277c-4ba2-9369-46a9996f811e",
   "metadata": {},
   "source": [
    "### 9️⃣ Kategorik Verilerin Dağılımını İnceleme (`groupBy()`)  \n",
    "Bu adımda **ocean_proximity_index sütunundaki farklı kategorilerin kaç kez tekrarlandığını buluyoruz.**  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac35fedb-87f0-462d-bac0-93c09252687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|ocean_proximity_index|count|\n",
      "+---------------------+-----+\n",
      "|                  0.0| 9136|\n",
      "|                  1.0| 6551|\n",
      "|                  2.0| 2658|\n",
      "|                  3.0| 2290|\n",
      "|                  4.0|    5|\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"ocean_proximity_index\").count().orderBy(\"count\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2426c8-2358-443e-9b2e-23e5a6d5ea50",
   "metadata": {},
   "source": [
    "### 🔟 Kategorik Değerlerin Sayısal Karşılıklarını Görme (`distinct()`)  \n",
    "Bu adımda **orijinal kategorik değerlerin (ocean_proximity) sayısal karşılıklarını (ocean_proximity_index) inceliyoruz.**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f177d5c-0c12-412e-8714-99c3180841b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|ocean_proximity|ocean_proximity_index|\n",
      "+---------------+---------------------+\n",
      "|         INLAND|                  1.0|\n",
      "|     NEAR OCEAN|                  2.0|\n",
      "|       NEAR BAY|                  3.0|\n",
      "|         ISLAND|                  4.0|\n",
      "|      <1H OCEAN|                  0.0|\n",
      "+---------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ocean_proximity\", \"ocean_proximity_index\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50cba8-f7cb-4190-bc66-733e6376b6f3",
   "metadata": {},
   "source": [
    "###  Bağımsız Değişkenleri Tek Bir Sütunda Birleştirme (`VectorAssembler`)  \n",
    "Bu adımda, **modelde kullanacağımız tüm bağımsız değişkenleri (`features`) tek bir sütunda birleştiriyoruz.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **Hangi değişkenleri kullanacağımızı belirle (`feature_cols`).**  \n",
    "2️⃣ **Tüm bağımsız değişkenleri `features` sütununda birleştir (`VectorAssembler`).**  \n",
    "3️⃣ **Yeni oluşturulan `features` sütununu ve hedef değişkeni (`median_house_value`) göster.**  \n",
    "\n",
    "📌 **Bu işlem neden önemli?**  \n",
    "- **Makine öğrenmesi modelleri, özellikleri tek bir sütunda vektör olarak bekler.**  \n",
    "- **Spark ML için tüm bağımsız değişkenleri tek bir \"features\" sütununa çevirmeliyiz.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e9d6f2-d511-46ef-b568-0a55ad721ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+------------------+\n",
      "|features                                                   |median_house_value|\n",
      "+-----------------------------------------------------------+------------------+\n",
      "|[-122.23,37.88,41.0,880.0,129.0,322.0,126.0,8.3252,3.0]    |452600.0          |\n",
      "|[-122.22,37.86,21.0,7099.0,1106.0,2401.0,1138.0,8.3014,3.0]|358500.0          |\n",
      "|[-122.24,37.85,52.0,1467.0,190.0,496.0,177.0,7.2574,3.0]   |352100.0          |\n",
      "|[-122.25,37.85,52.0,1274.0,235.0,558.0,219.0,5.6431,3.0]   |341300.0          |\n",
      "|[-122.25,37.85,52.0,1627.0,280.0,565.0,259.0,3.8462,3.0]   |342200.0          |\n",
      "+-----------------------------------------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Modelde kullanacağımız bağımsız değişkenler (features)\n",
    "feature_cols = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\",\n",
    "                \"population\", \"households\", \"median_income\", \"ocean_proximity_index\"]\n",
    "\n",
    "# VectorAssembler ile tüm bağımsız değişkenleri tek bir \"features\" sütununa çevir\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Yeni oluşan 'features' sütununu ve hedef değişkeni gösterelim\n",
    "df.select(\"features\", \"median_house_value\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e51732-7608-40ef-989e-f5b7016ab3d6",
   "metadata": {},
   "source": [
    "### 1️⃣1️⃣ Veriyi Eğitim ve Test Olarak Bölme  \n",
    "Bu adımda **veriyi eğitim (%80) ve test (%20) olacak şekilde ikiye ayırıyoruz.**  \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f16d1382-7201-4690-8615-79e5c7dbc796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim veri seti boyutu: 16560\n",
      "Test veri seti boyutu: 4080\n"
     ]
    }
   ],
   "source": [
    "# Veriyi eğitim (%80) ve test (%20) olarak böl\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Eğitim ve test veri sayısını göster\n",
    "print(\"Eğitim veri seti boyutu:\", train_data.count())\n",
    "print(\"Test veri seti boyutu:\", test_data.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24523154-d7ec-4f49-b079-9cbb58ab0607",
   "metadata": {},
   "source": [
    "###  Lineer Regresyon Modelini Eğitme  \n",
    "Bu adımda **Lineer Regresyon modeli oluşturuyor ve eğitim verisiyle eğitiyoruz.**  \n",
    "\n",
    "📌 **Bu işlem neden önemli?**  \n",
    "- **Model bağımsız değişkenlerin fiyat üzerindeki etkisini öğrenir.**  \n",
    "- **Katsayılar, hangi değişkenlerin fiyatı nasıl etkilediğini gösterir.**  \n",
    "- **Elde edilen denklem, modelin öğrendiği fiyat tahmin formülüdür.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86aa6099-69ec-4e5f-99e6-377e6fba23ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katsayılar (Coefficients): [-42998.21475945207,-42706.99559442026,1144.740818422602,-5.135908972631532,80.23713743850453,-46.47731286507485,87.57201183285588,39356.34067186512,-1701.0152504894525]\n",
      "Sabit Terim (Intercept): -3603816.30374622\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Lineer Regresyon Modelini Tanımla\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n",
    "\n",
    "# Modeli eğitim verisi ile eğit\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Modelin katsayılarını ve sabit terimini yazdır\n",
    "print(\"Katsayılar (Coefficients):\", lr_model.coefficients)\n",
    "print(\"Sabit Terim (Intercept):\", lr_model.intercept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f458a93-72be-48ef-b38b-2aa4396cf845",
   "metadata": {},
   "source": [
    "###  Modeli Test Verisi Üzerinde Çalıştırma ve Tahmin Yapma  \n",
    "Bu adımda, **eğittiğimiz Lineer Regresyon modelini test verisi üzerinde çalıştırıyoruz** ve **ev fiyatlarını tahmin ediyoruz.**  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64c0cab-cc4c-4b28-bbc6-71a25ab193ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|median_house_value|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|[-124.3,41.84,17....|          103600.0| 100332.6859256993|\n",
      "|[-124.23,40.54,52...|          106700.0|190939.19476755708|\n",
      "|[-124.23,41.75,11...|           73200.0| 74378.07399941469|\n",
      "|[-124.19,40.73,21...|           90100.0|161986.40932086855|\n",
      "|[-124.18,40.78,34...|           67000.0| 119303.9588295496|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modeli test verisi üzerinde çalıştır ve tahmin yap\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# İlk 5 tahmini göster\n",
    "predictions.select(\"features\", \"median_house_value\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94747207-f1f6-4fc8-bcf3-0426f53d439d",
   "metadata": {},
   "source": [
    "### 1️⃣4️⃣ Modelin Performansını Değerlendirme (RMSE ve R²)  \n",
    "Bu adımda, **Lineer Regresyon modelinin tahmin başarısını ölçüyoruz.**  \n",
    "\n",
    "📌 **Ölçülen metrikler:**  \n",
    "- **RMSE (Kök Ortalama Kare Hatası)** → Tahminlerin hata miktarını ölçer (Daha düşük RMSE = Daha iyi model).  \n",
    "- **R² (R-Kare)** → Modelin veri setini ne kadar iyi açıkladığını gösterir (1'e yakınsa model iyi çalışıyor demektir).  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **RMSE’yi hesapla.**  \n",
    "2️⃣ **R² (R-Kare) değerini hesapla.**  \n",
    "3️⃣ **Sonuçları ekrana yazdır.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2900af2-3e3d-4cc2-877a-9235e90259b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 71796.88026080727\n",
      "R-Kare (R²): 0.6274325466994999\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Modelin performansını değerlendirme\n",
    "evaluator = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "# R² (R-Kare) metriğini hesapla\n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = r2_evaluator.evaluate(predictions)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-Kare (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27abba-871c-4922-933c-894e13235e7d",
   "metadata": {},
   "source": [
    "### 1️⃣5️⃣ StandardScaler ile Özellikleri Ölçeklendirme  \n",
    "Bu adımda, **bağımsız değişkenleri ölçeklendirerek modelin daha iyi öğrenmesini sağlıyoruz.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **StandardScaler kullanarak tüm bağımsız değişkenleri ölçekle.**  \n",
    "2️⃣ **Yeni ölçeklenmiş özellikleri (\"scaled_features\") oluştur.**  \n",
    "3️⃣ **Sonuçları ekrana yazdır ve ölçeklemenin doğru çalıştığını kontrol et.**  \n",
    "\n",
    "📌 **Bu işlem neden önemli?**  \n",
    "- **Bazı değişkenler çok büyük, bazıları çok küçük olabilir.**  \n",
    "- **Büyük değerli değişkenler modelin diğer değişkenleri göz ardı etmesine neden olabilir.**  \n",
    "- **Ölçekleme ile tüm değişkenleri aynı seviyeye getirerek modelin daha iyi öğrenmesini sağlıyoruz.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1d09749-54b2-4f78-b047-f0e4b8d4aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|scaled_features                                                                                                                                                                     |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[-1.3278030546902004,1.0525227849496404,0.9821188656747666,-0.804799599801809,-0.9752042257163941,-0.9744049915469923,-0.977009185045236,2.3447089561176147,2.0817600895927892]     |\n",
      "|[-1.3228118684350991,1.0431592803959744,-0.6070042082805048,2.0458405373571247,1.3550553701672787,0.8614179998296625,1.6699205725917976,2.3321814648403056,2.0817600895927892]      |\n",
      "|[-1.3327942409452944,1.0384775281191432,1.8561365563501657,-0.5357329073251578,-0.8297120708045169,-0.8207574684591915,-0.8436164798678757,1.782656217213844,2.0817600895927892]    |\n",
      "|[-1.3377854272003955,1.0384775281191432,1.8561365563501657,-0.6241994689060669,-0.722381792590837,-0.7660095004623889,-0.7337636638394612,0.9329449075937323,2.0817600895927892]    |\n",
      "|[-1.3377854272003955,1.0384775281191432,1.8561365563501657,-0.4623927526466838,-0.6150515143771571,-0.7598282782692015,-0.6291419342885903,-0.012880683843038048,2.0817600895927892]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# StandardScaler ile tüm özellikleri ölçekleyelim\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(df)\n",
    "df = scaler_model.transform(df)\n",
    "\n",
    "# Ölçeklenmiş özellikleri görelim\n",
    "df.select(\"scaled_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eed29af-97a4-4441-a7bc-1910a0fa62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83282bc-4464-44f9-a9a8-9e0a788b5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()\n",
    "test_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b422cba-fada-4b24-b827-280adf177786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model eğitiminden önce veriyi tekrar bölelim (Ölçeklenmiş veriye göre)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Bölünmüş veri kümelerini kontrol et\n",
    "train_data.printSchema()\n",
    "test_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643081f1-df9a-4480-9fb7-0d4684a1d272",
   "metadata": {},
   "source": [
    "### 1️⃣6️⃣ Random Forest Modeli ile Tahmin Yapma  \n",
    "Bu adımda, **Random Forest algoritması kullanarak ev fiyatlarını tahmin ediyoruz.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **Random Forest modelini oluştur (`RandomForestRegressor`).**  \n",
    "2️⃣ **Modeli eğitim verisi ile eğit (`fit`).**  \n",
    "3️⃣ **Test verisi üzerinde tahmin yap (`transform`).**  \n",
    "4️⃣ **Tahmin edilen fiyatları gerçek fiyatlarla karşılaştır (`show`).**  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "376ee382-8e9d-4988-85e2-6dfd8edf1a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
      "|scaled_features                                                                                                                                                                     |median_house_value|prediction        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
      "|[-2.3609786094955965,2.9064966865751956,-0.9248288230715591,0.018902012430801425,-0.01638707367418689,-0.1602497255300247,-0.11387991625055117,-0.441815668795915,1.08628877737642] |103600.0          |138007.8191091182 |\n",
      "|[-2.3260403057099097,2.2978688905870066,1.8561365563501657,0.02669440386538928,-0.20242622257789875,-0.2414886457833447,-0.1688063242647584,-0.41586586543577647,1.08628877737642]  |106700.0          |159340.16483564983|\n",
      "|[-2.3260403057099097,2.864360916083704,-1.4015657452581405,0.23983922839970417,0.18634789628498627,-0.07282958308351734,-0.053722421758800404,-0.731737609785048,1.08628877737642]  |73200.0           |122288.79640078184|\n",
      "|[-2.3060755606895125,2.3868221838468173,-0.6070042082805048,1.4018223040867757,1.235799505485412,1.3082320612229223,1.2357403949556833,-0.17600125303790423,1.08628877737642]       |90100.0           |161659.24522996266|\n",
      "|[-2.3010843744344185,2.4102309452309805,0.42592578979042156,-0.47843591148259995,-0.41470166171162126,-0.4198610576438951,-0.47744042643982754,-0.9000691942591308,1.08628877737642]|67000.0           |116345.42812010096|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Random Forest modelini scaled_features ile tanımla\n",
    "rf = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"median_house_value\", numTrees=50)\n",
    "\n",
    "# Modeli eğit\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Modeli test verisi üzerinde çalıştır\n",
    "predictions_rf = rf_model.transform(test_data)\n",
    "\n",
    "# İlk 5 tahmini görelim\n",
    "predictions_rf.select(\"scaled_features\", \"median_house_value\", \"prediction\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30c6d3-b059-4f0e-a65c-0b634e45d912",
   "metadata": {},
   "source": [
    "### 1️⃣7️⃣ Random Forest Modelinin Performansını Değerlendirme  \n",
    "Bu adımda, **Random Forest modelinin tahmin başarısını ölçüyoruz.**  \n",
    "\n",
    "📌 **Ölçülen metrikler:**  \n",
    "- **RMSE (Kök Ortalama Kare Hatası)** → Modelin tahminlerinin hata miktarını ölçer.  \n",
    "- **R² (R-Kare)** → Modelin veri setini ne kadar iyi açıkladığını gösterir (1'e yakınsa model iyi çalışıyor demektir). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65802b23-671c-49cd-8517-e04eea334d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 71397.04195332128\n",
      "Random Forest R-Kare (R²): 0.6315706635644186\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# RMSE (Hata Metrikleri)\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse_rf = evaluator_rmse.evaluate(predictions_rf)\n",
    "\n",
    "# R² (Modelin ne kadar iyi öğrendiğini gösteren metrik)\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2_rf = evaluator_r2.evaluate(predictions_rf)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "print(f\"Random Forest R-Kare (R²): {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f73f4d-31d0-442f-a971-a9856803e0f8",
   "metadata": {},
   "source": [
    "### 1️⃣8️⃣ Yeni Öznitelikler Ekleyerek Modeli Güçlendirme  \n",
    "Bu adımda, **veri setine yeni öznitelikler ekleyerek modelin daha iyi tahmin yapmasını sağlıyoruz.**  \n",
    "\n",
    "📌 **Eklenen öznitelikler:**  \n",
    "1️⃣ **\"rooms_per_person\"** → Kişi başına düşen oda sayısı.  \n",
    "2️⃣ **\"rooms_per_household\"** → Hane başına düşen oda sayısı.  \n",
    "3️⃣ **\"income_per_household\"** → Hane başına düşen gelir.  \n",
    "\n",
    "📌 **Bu işlem neden önemli?**  \n",
    "- **Daha fazla bilgi içeren bir veri seti, modelin daha doğru tahmin yapmasını sağlar.**  \n",
    "- **Özellikle gelir ve oda sayısı gibi faktörler, konut fiyatlarını belirlemede önemli olabilir.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "018a46cf-63e4-478d-b207-e32d1dd289de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+--------------------+\n",
      "|  rooms_per_person|rooms_per_household|income_per_household|\n",
      "+------------------+-------------------+--------------------+\n",
      "| 2.732919254658385|  6.984126984126984| 0.06607301587301588|\n",
      "|2.9566847147022073|  6.238137082601054|0.007294727592267135|\n",
      "|2.9576612903225805|  8.288135593220339| 0.04100225988700565|\n",
      "| 2.283154121863799| 5.8173515981735155|0.025767579908675797|\n",
      "| 2.879646017699115|  6.281853281853282| 0.01485019305019305|\n",
      "+------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Yeni öznitelikleri hesapla\n",
    "df = df.withColumn(\"rooms_per_person\", col(\"total_rooms\") / col(\"population\"))\n",
    "df = df.withColumn(\"rooms_per_household\", col(\"total_rooms\") / col(\"households\"))\n",
    "df = df.withColumn(\"income_per_household\", col(\"median_income\") / col(\"households\"))\n",
    "\n",
    "# Yeni eklenen öznitelikleri görelim\n",
    "df.select(\"rooms_per_person\", \"rooms_per_household\", \"income_per_household\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fab41f-4490-414e-9a77-be46f31186b3",
   "metadata": {},
   "source": [
    "### 1️⃣9️⃣ Yeni Özniteliklerle \"features\" Vektörünü Güncelleme  \n",
    "Bu adımda, **veri setindeki eski \"features\" sütununu kaldırıyor ve yeni eklenen değişkenlerle yeniden oluşturuyoruz.**  \n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **Eski \"features\" sütununu kaldır.**  \n",
    "2️⃣ **Yeni bağımsız değişkenler listesini oluştur.**  \n",
    "3️⃣ **Tüm değişkenleri birleştirerek yeni \"features\" sütununu oluştur.**  \n",
    "4️⃣ **Yeni \"features\" sütununun ilk 5 satırını göster.**  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfc3e4c9-eb63-4bd9-8f3f-582cce52055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|[-122.23,37.88,41.0,880.0,129.0,322.0,126.0,8.3252,3.0,2.732919254658385,6.984126984126984,0.06607301587301588]      |\n",
      "|[-122.22,37.86,21.0,7099.0,1106.0,2401.0,1138.0,8.3014,3.0,2.9566847147022073,6.238137082601054,0.007294727592267135]|\n",
      "|[-122.24,37.85,52.0,1467.0,190.0,496.0,177.0,7.2574,3.0,2.9576612903225805,8.288135593220339,0.04100225988700565]    |\n",
      "|[-122.25,37.85,52.0,1274.0,235.0,558.0,219.0,5.6431,3.0,2.283154121863799,5.8173515981735155,0.025767579908675797]   |\n",
      "|[-122.25,37.85,52.0,1627.0,280.0,565.0,259.0,3.8462,3.0,2.879646017699115,6.281853281853282,0.01485019305019305]     |\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Önce eski 'features' sütununu düşür\n",
    "df = df.drop(\"features\")\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Güncellenmiş bağımsız değişkenler listesi (yeni eklenen özniteliklerle)\n",
    "feature_cols = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\",\n",
    "                \"population\", \"households\", \"median_income\", \"ocean_proximity_index\",\n",
    "                \"rooms_per_person\", \"rooms_per_household\", \"income_per_household\"]\n",
    "\n",
    "# Yeni features vektörünü oluştur\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Yeni features sütununu görelim\n",
    "df.select(\"features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2a3bd-9fa1-4367-8fa3-70f9d5a23329",
   "metadata": {},
   "source": [
    "###   StandardScaler ile Özellikleri Ölçeklendirme  \n",
    "Bu adımda, **bağımsız değişkenleri ölçeklendirerek modelin daha iyi öğrenmesini sağlıyoruz.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **StandardScaler kullanarak tüm bağımsız değişkenleri ölçekle.**  \n",
    "2️⃣ **Yeni ölçeklenmiş özellikleri (\"scaled_features\") oluştur.**  \n",
    "3️⃣ **Sonuçları ekrana yazdır ve ölçeklemenin doğru çalıştığını kontrol et.**  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86fba1d5-decc-409b-8c22-15798d9fadd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|scaled_features                                                                                                                                                                                                                                |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[-1.3278030546902004,1.0525227849496404,0.9821188656747666,-0.804799599801809,-0.9752042257163941,-0.9744049915469923,-0.977009185045236,2.3447089561176147,2.0817600895927892,0.6596305965114945,0.6285442264151613,0.420730403000244]        |\n",
      "|[-1.3228118684350991,1.0431592803959744,-0.6070042082805048,2.0458405373571247,1.3550553701672787,0.8614179998296625,1.6699205725917976,2.3321814648403056,2.0817600895927892,0.8548850580243383,0.32703343493534437,-0.07186095273688532]     |\n",
      "|[-1.3327942409452944,1.0384775281191432,1.8561365563501657,-0.5357329073251578,-0.8297120708045169,-0.8207574684591915,-0.8436164798678757,1.782656217213844,2.0817600895927892,0.8557372036005377,1.155592470660819,0.21062497050590706]      |\n",
      "|[-1.3377854272003955,1.0384775281191432,1.8561365563501657,-0.6241994689060669,-0.722381792590837,-0.7660095004623889,-0.7337636638394612,0.9329449075937323,2.0817600895927892,0.26717213221650854,0.15696227955717026,0.08295075806708226]   |\n",
      "|[-1.3377854272003955,1.0384775281191432,1.8561365563501657,-0.4623927526466838,-0.6150515143771571,-0.7598282782692015,-0.6291419342885903,-0.012880683843038048,2.0817600895927892,0.7876622198971135,0.344702448698221,-0.008542385932623032]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Önce eski 'scaled_features' sütununu kaldır\n",
    "df = df.drop(\"scaled_features\")\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# StandardScaler ile ölçekleme yap\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(df)\n",
    "df = scaler_model.transform(df)\n",
    "\n",
    "# Yeni ölçeklenmiş özellikleri kontrol edelim\n",
    "df.select(\"scaled_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d68455a0-9a68-48b2-bcd2-7085dcf64402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- rooms_per_person: double (nullable = true)\n",
      " |-- rooms_per_household: double (nullable = true)\n",
      " |-- income_per_household: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = false)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      " |-- ocean_proximity_index: double (nullable = false)\n",
      " |-- rooms_per_person: double (nullable = true)\n",
      " |-- rooms_per_household: double (nullable = true)\n",
      " |-- income_per_household: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model eğitiminden önce veriyi tekrar bölelim (Ölçeklenmiş yeni veriye göre)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Bölünmüş veri kümelerini kontrol edelim\n",
    "train_data.printSchema()\n",
    "test_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774dbf9-8fc1-4ff0-ba3e-12f9ffa95d1c",
   "metadata": {},
   "source": [
    "### 2️⃣0️⃣ Random Forest Modelini Yeniden Eğitme ve Tahmin Yapma  \n",
    "Bu adımda, **Random Forest modelini yeni eklenen özniteliklerle tekrar eğitiyoruz.**  \n",
    "\n",
    "📌 **Adımlar:**  \n",
    "1️⃣ **Random Forest modelini oluştur (`RandomForestRegressor`).**  \n",
    "2️⃣ **Modeli eğitim verisi ile eğit (`fit`).**  \n",
    "3️⃣ **Test verisi üzerinde tahmin yap (`transform`).**  \n",
    "4️⃣ **Tahmin edilen fiyatları gerçek fiyatlarla karşılaştır (`show`).**  \n",
    "\n",
    "📌 **Bu işlem neden önemli?**  \n",
    "- **Yeni eklenen özelliklerle modelin tahmin gücünü artırıyoruz.**  \n",
    "- **Random Forest, çok sayıda karar ağacı kullanarak daha güçlü tahminler yapar.**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "852bc315-4a2c-471e-bfcb-aac5c63e6e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
      "|scaled_features                                                                                                                                                                                                                                   |median_house_value|prediction        |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
      "|[-2.3609786094955965,2.9064966865751956,-0.9248288230715591,0.018902012430801425,-0.01638707367418689,-0.1602497255300247,-0.11387991625055117,-0.441815668795915,1.08628877737642,0.15266724103536014,0.17848964806081366,-0.07728430746022635]  |103600.0          |152871.28191234655|\n",
      "|[-2.3260403057099097,2.2978688905870066,1.8561365563501657,0.02669440386538928,-0.20242622257789875,-0.2414886457833447,-0.1688063242647584,-0.41586586543577647,1.08628877737642,0.31550249219648235,0.3088319462813734,-0.07364506458701547]    |106700.0          |185102.79817924427|\n",
      "|[-2.3260403057099097,2.864360916083704,-1.4015657452581405,0.23983922839970417,0.18634789628498627,-0.07282958308351734,-0.053722421758800404,-0.731737609785048,1.08628877737642,0.3274175649713336,0.471264440154573,-0.08959602110610608]      |73200.0           |148250.23091802117|\n",
      "|[-2.3060755606895125,2.3868221838468173,-0.6070042082805048,1.4018223040867757,1.235799505485412,1.3082320612229223,1.2357403949556833,-0.17600125303790423,1.08628877737642,-0.015924040303526482,0.17340134460739248,-0.1025047387809988]       |90100.0           |187881.40524921753|\n",
      "|[-2.3010843744344185,2.4102309452309805,0.42592578979042156,-0.47843591148259995,-0.41470166171162126,-0.4198610576438951,-0.47744042643982754,-0.9000691942591308,1.08628877737642,-0.26280535983708453,-0.16446614700440443,-0.0758721883640769]|67000.0           |119589.5070416373 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Random Forest modelini scaled_features ile tanımla\n",
    "rf = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"median_house_value\", numTrees=50)\n",
    "\n",
    "# Modeli eğit\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Modeli test verisi üzerinde çalıştır\n",
    "predictions_rf = rf_model.transform(test_data)\n",
    "\n",
    "# İlk 5 tahmini görelim\n",
    "predictions_rf.select(\"scaled_features\", \"median_house_value\", \"prediction\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b30a2b5-6d13-45a4-ae9d-e01670b263c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Yeni Özellikler) RMSE: 67864.08924408912\n",
      "Random Forest (Yeni Özellikler) R-Kare (R²): 0.667130643626022\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# RMSE (Hata Metrikleri)\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse_rf = evaluator_rmse.evaluate(predictions_rf)\n",
    "\n",
    "# R² (Modelin ne kadar iyi öğrendiğini gösteren metrik)\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2_rf = evaluator_r2.evaluate(predictions_rf)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(f\"Random Forest (Yeni Özellikler) RMSE: {rmse_rf}\")\n",
    "print(f\"Random Forest (Yeni Özellikler) R-Kare (R²): {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05898a06-4437-4df0-924d-8bb195231951",
   "metadata": {},
   "source": [
    "### 2️⃣1️⃣ XGBoost Modeli ile Ev Fiyatlarını Tahmin Etme  \n",
    "Bu adımda, **XGBoost algoritmasını kullanarak konut fiyatlarını tahmin ediyoruz.**  \n",
    "\n",
    "📌 **Neden XGBoost kullanıyoruz?**  \n",
    "- **XGBoost, karar ağaçlarından daha güçlü bir makine öğrenmesi modelidir.**  \n",
    "- **Özellikle büyük veri setlerinde ve karmaşık ilişkilerde çok başarılıdır.**  \n",
    "- **Random Forest yerine XGBoost kullanarak modelin doğruluğunu artırmayı hedefliyoruz.**  \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78da6c0e-ab4e-4adf-a3aa-809a9c4fad4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerçek: 103600.0 Tahmin: 119472.546875\n",
      "Gerçek: 106700.0 Tahmin: 91329.21875\n",
      "Gerçek: 73200.0 Tahmin: 110369.7421875\n",
      "Gerçek: 90100.0 Tahmin: 114152.0234375\n",
      "Gerçek: 67000.0 Tahmin: 75674.1171875\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Pandas ve NumPy kullanarak veriyi XGBoost için uygun hale getirelim\n",
    "train_pd = train_data.select(\"scaled_features\", \"median_house_value\").toPandas()\n",
    "test_pd = test_data.select(\"scaled_features\", \"median_house_value\").toPandas()\n",
    "\n",
    "# Feature ve Label ayrımı\n",
    "X_train = np.array(train_pd[\"scaled_features\"].tolist())  # Bağımsız değişkenler (features)\n",
    "y_train = np.array(train_pd[\"median_house_value\"])        # Bağımlı değişken (label)\n",
    "\n",
    "X_test = np.array(test_pd[\"scaled_features\"].tolist())    # Test özellikleri\n",
    "y_test = np.array(test_pd[\"median_house_value\"])          # Test gerçek değerleri\n",
    "\n",
    "# XGBoost modelini tanımla\n",
    "xgb_model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Modeli eğit\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Model ile tahmin yap\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# İlk 5 tahmini göster\n",
    "for i in range(5):\n",
    "    print(f\"Gerçek: {y_test[i]} Tahmin: {y_pred[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc96c25-7c47-4233-beef-1098a60d7e6c",
   "metadata": {},
   "source": [
    "### 2️⃣2️⃣ XGBoost Modelinin Performansını Değerlendirme  \n",
    "Bu adımda, **XGBoost modelinin tahmin başarısını ölçüyoruz.**  \n",
    "\n",
    "📌 **Ölçülen metrikler:**  \n",
    "- **RMSE (Kök Ortalama Kare Hatası)** → Modelin tahminlerinin hata miktarını ölçer.  \n",
    "- **R² (R-Kare)** → Modelin veri setini ne kadar iyi açıkladığını gösterir (1'e yakınsa model iyi çalışıyor demektir).  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5ade7d4-eda3-45c3-bbe3-74e94407b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 46296.1434138838\n",
      "XGBoost R-Kare (R²): 0.8450885940863098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# RMSE'yi hesapla\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# R² (Modelin doğruluk oranı)\n",
    "r2_xgb = r2_score(y_test, y_pred)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(f\"XGBoost RMSE: {rmse_xgb}\")\n",
    "print(f\"XGBoost R-Kare (R²): {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999f2f1-8258-46ab-ab69-4aec113d25b0",
   "metadata": {},
   "source": [
    "### 📌 Konut Fiyatlarının Tahmini - Proje Özeti  \n",
    "\n",
    "Bu projede, **California Housing Prices** veri seti kullanılarak konut fiyatlarının tahmini için farklı makine öğrenmesi modelleri uygulanmıştır.  \n",
    "\n",
    "#### 📌 Adımlar:  \n",
    "1️⃣ **Veri yükleme ve ön işleme**  \n",
    "   - Eksik veriler dolduruldu.  \n",
    "   - Kategorik veriler sayısal hale getirildi.  \n",
    "\n",
    "2️⃣ **Yeni öznitelikler oluşturma**  \n",
    "   - Kişi başına düşen oda sayısı, hane başına düşen gelir gibi ek özellikler eklendi.  \n",
    "\n",
    "3️⃣ **Özellik mühendisliği ve ölçekleme**  \n",
    "   - Veriler `VectorAssembler` ile birleştirildi.  \n",
    "   - `StandardScaler` ile ölçeklendirildi.  \n",
    "\n",
    "4️⃣ **Farklı modellerin eğitilmesi**  \n",
    "   - **Lineer Regresyon**  \n",
    "   - **Random Forest**  \n",
    "   - **XGBoost**  \n",
    "\n",
    "5️⃣ **Model performanslarının karşılaştırılması**  \n",
    "   - RMSE ve R² metrikleri hesaplandı.  \n",
    "   - **En iyi sonuç XGBoost modeli ile alındı (RMSE: ~46,296, R²: ~0.845).**  \n",
    "\n",
    "#### 📌 Sonuç:  \n",
    "✅ **XGBoost modeli, konut fiyatlarını en doğru şekilde tahmin etti.**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe39ce9-a908-484b-842d-15ea7b1bf4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (veri_uygulamalari)",
   "language": "python",
   "name": "veri_uygulamalari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
